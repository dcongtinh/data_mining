{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from urllib.parse import unquote\n",
    "import re\n",
    "import time\n",
    "import requests\n",
    "import urllib.request\n",
    "import lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driverPath = 'D:/book_social_network/chromedriver.exe'\n",
    "driver = webdriver.Chrome(driverPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = []\n",
    "authors = []\n",
    "descriptions = []\n",
    "languages = []\n",
    "pages = []\n",
    "genres = []\n",
    "publishers = []\n",
    "isbn10 = []\n",
    "isbn13 = []\n",
    "dimensions = []\n",
    "shipping_weight = []\n",
    "published_date = []\n",
    "book_images = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_fields = [titles, \n",
    "               authors, \n",
    "               descriptions, \n",
    "               languages, \n",
    "               pages, \n",
    "               genres, \n",
    "               publishers, \n",
    "               isbn10, \n",
    "               isbn13, \n",
    "               dimensions, \n",
    "               shipping_weight, \n",
    "               published_date, \n",
    "               book_images\n",
    "              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# How many pages to loop through in a certain url\n",
    "for i in range(2, 3):\n",
    "    print(\"Current page is: \" + str(i))\n",
    "    driver.get(\"https://www.amazon.com/s?i=stripbooks&rh=n:283155,n:1000,n:5,n:3952&page=\" + str(i))\n",
    "    time.sleep(4)\n",
    "    content = driver.page_source\n",
    "    soup = BeautifulSoup(content)\n",
    "    time.sleep(3)\n",
    "    for div in soup.find_all('div', attrs = {'data-index':[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}):\n",
    "        links = div.find('a', attrs = {'class':'a-link-normal a-text-normal'})\n",
    "        href_value = unquote(links.attrs.get('href'))\n",
    "        book_url = 'https://www.amazon.com' + href_value\n",
    "        driver.get(book_url)\n",
    "        time.sleep(4)\n",
    "        # Author identify code section\n",
    "        author_href = div.find('a', attrs={'class':'a-size-base a-link-normal'})\n",
    "        if (author_href):\n",
    "            author_href_value = unquote(author_href.attrs.get('href'))\n",
    "            author_regx = re.search('/e/B\\w+\\?', author_href_value)\n",
    "            author_code = author_href_value[author_regx.start()+3:author_regx.end()-1]\n",
    "        # Book publication date section\n",
    "        published_div = div.find('div', attrs={'class':'sg-col-4-of-12 sg-col-8-of-16 sg-col-12-of-32 sg-col-12-of-20 sg-col-12-of-36 sg-col sg-col-12-of-24 sg-col-12-of-28'})\n",
    "        book_publication = published_div.find('span', attrs={'class':'a-size-base a-color-secondary a-text-normal'}).text\n",
    "        # Assign new data source\n",
    "        book_content = driver.page_source\n",
    "        book_soup = BeautifulSoup(book_content)\n",
    "        time.sleep(3)\n",
    "        # Center div book data to get\n",
    "        book_middle_data = book_soup.find('div', attrs={'id':'centerCol'})\n",
    "        # Title feature div\n",
    "        title_feature_div = book_soup.find('div', attrs = {'id':'title_feature_div'})\n",
    "        if (book_middle_data):\n",
    "            # Book title section\n",
    "            book_title = book_middle_data.find('span', attrs={'id':'productTitle'}).text\n",
    "            # Book author section\n",
    "            if (author_href == None):\n",
    "                byline_info = book_middle_data.find('div', attrs = {'id':'bylineInfo'})\n",
    "                book_author = byline_info.find('a', attrs = {'class':'a-link-normal'}).text\n",
    "            else:\n",
    "                book_author = book_middle_data.find('a', attrs = {'data-asin':author_code}).text\n",
    "        else:\n",
    "            # Book title section\n",
    "            book_title = title_feature_div.find('span', attrs = {'id':'productTitle'}).text\n",
    "            # Book author section\n",
    "            if (author_href):\n",
    "                book_author = title_feature_div.find('a', attrs = {'data-asin':author_code}).text\n",
    "                # Data assignment section at the bottom\n",
    "            else:\n",
    "                byline_info = title_feature_div.find('div', attrs = {'id':'bylineInfo'})\n",
    "                book_author = byline_info.find('a', attrs={'class':'a-link-normal'}).text\n",
    "        # Book description section\n",
    "        if (book_middle_data):\n",
    "            book_desc = book_middle_data.find('noscript')\n",
    "            if (book_desc == None):\n",
    "                book_desc = \"Null\"\n",
    "            else:\n",
    "                book_desc = book_desc.get_text().strip()\n",
    "        else:\n",
    "            book_desc_feature = book_soup.find('div', attrs = {'id':'bookDescription_feature_div'})\n",
    "            book_desc = book_desc_feature.find('noscript').get_text().strip()\n",
    "        # Book genre section\n",
    "            # Go to the data insert section\n",
    "        # Book details section\n",
    "        book_detail_table = book_soup.find('table', attrs={'id':'productDetailsTable'})\n",
    "        ul_tag = book_detail_table.find('ul')\n",
    "        item_rows = ul_tag.find_all('li')\n",
    "        for item_row in item_rows:\n",
    "            # Book page section\n",
    "            if(re.search('^Paperback: ', item_row.text)):\n",
    "                book_page_start = re.search('^Paperback: ', item_row.text)\n",
    "                book_page_end = re.search(' pages', item_row.text)\n",
    "                book_page = item_row.text[book_page_start.end():book_page_end.start()]\n",
    "            # Book language section\n",
    "            if (re.search('^Language: ', item_row.text)):\n",
    "                book_language_regx = re.search('^Language: ', item_row.text)\n",
    "                book_lang = item_row.text[book_language_regx.end():]\n",
    "            # Book publisher section\n",
    "            if (re.search('^Publisher: ', item_row.text)):\n",
    "                book_publisher_regx = re.search('^Publisher: ', item_row.text)\n",
    "                # Check whether the string match the (Month Date, Year)\n",
    "                if (re.search(\" \\(\\w+ \\d+, \\d+\\)\", item_row.text)):\n",
    "                    published_date_regx = re.search(\" \\(\\w+ \\d+, \\d+\\)\", item_row.text)\n",
    "                    book_publisher = item_row.text[book_publisher_regx.end():published_date_regx.start()]\n",
    "                # Check wether the string contains the symbol ; pattern\n",
    "                elif (re.search(r';', item_row.text)):\n",
    "                    string_spliter = re.search(r';', item_row.text)\n",
    "                    book_publisher = item_row.text[book_publisher_regx.end():string_spliter.start()]\n",
    "                elif (re.search(\" \\(\\d+\\)\", item_row.text)):\n",
    "                    year_publish = re.search(\" \\(\\d+\\)\", item_row.text)\n",
    "                    book_publisher = item_row.text[book_publisher_regx.end():year_publish.start()]\n",
    "                else:\n",
    "                    month_year = re.search(\" \\(\\w+ \\d+\\)\", item_row.text)\n",
    "                    book_publisher = item_row.text[book_publisher_regx.end():month_year.start()]\n",
    "            # Book isbn-10 section\n",
    "            if (re.search(\"^ISBN-10: \", item_row.text)):\n",
    "                book_isbn10_regx = re.search(\"^ISBN-10: \", item_row.text)\n",
    "                book_isbn10 = item_row.text[book_isbn10_regx.end():]\n",
    "                # For debug purpose\n",
    "                print(book_isbn10)\n",
    "            # Book isbn-13 section\n",
    "            if (re.search(\"^ISBN-13: \", item_row.text)):\n",
    "                book_isbn13_regx = re.search(\"^ISBN-13: \", item_row.text)\n",
    "                book_isbn13 = item_row.text[book_isbn13_regx.end():]\n",
    "            # Book dimensions section\n",
    "            if (re.search(\"Product Dimensions: \", item_row.text)):\n",
    "                book_dimension_start = re.search(\"Product Dimensions: \", item_row.text)\n",
    "                book_dimension_end = re.search(' inches', item_row.text)\n",
    "                book_dim = item_row.text[book_dimension_start.end():book_dimension_end.start()].strip()\n",
    "            # Book weight\n",
    "            if (re.search(\"^Shipping Weight: \", item_row.text)):\n",
    "                book_weight_start = re.search(\"^Shipping Weight: \", item_row.text)\n",
    "                book_weight_end = re.search(\" \\(View shipping rates and policies\\)\", item_row.text)\n",
    "                if (book_weight_end):\n",
    "                    book_weight = item_row.text[book_weight_start.end():book_weight_end.start()]\n",
    "                else:\n",
    "                    book_weight = item_row.text[book_weight_start.start():book_weight_start.end()]\n",
    "        # Book image section\n",
    "        if (book_middle_data):\n",
    "            book_image_div = book_soup.find('div', attrs={'id':'booksImageBlock_feature_div'})\n",
    "            image_scripts = book_image_div.find_all('script', attrs={'type':'text/javascript'})\n",
    "            for image_script in image_scripts:\n",
    "                if (re.search('\\'imageGalleryData\\' : \\[\\{\"mainUrl\":\"https://images-na.ssl-images-amazon.com/images/I/[\\Wa-zA-Z0-9]+.jpg', str(image_script))):\n",
    "                    img_url_end = re.search('\\'imageGalleryData\\' : \\[\\{\"mainUrl\":\"https://images-na.ssl-images-amazon.com/images/I/[\\Wa-zA-Z0-9]+.jpg', str(image_script))\n",
    "                    img_url_start = re.search('\\'imageGalleryData\\' : \\[\\{\"mainUrl\":\"', str(image_script))\n",
    "                    book_img_url = str(image_script)[img_url_start.end():img_url_end.end()]\n",
    "        else:\n",
    "            book_image_div = book_soup.find('div', attrs = {'id':'mainImageContainer'})\n",
    "            book_image_tag = book_image_div.find('img', attrs = {'id':'imgBlkFront'}).attrs.get(\"src\")\n",
    "            book_img_url_regx = re.search(r\"https://images-na.ssl-images-amazon.com/images/I/([a-zA-Z0-9+\\-~$]*._)|([a-zA-Z0-9]*._)\", book_image_tag)\n",
    "            if (book_img_url_regx):\n",
    "                book_img_url = book_image_tag[book_img_url_regx.start():book_img_url_regx.end()-2] + \".jpg\"\n",
    "        # Insert data into data list section\n",
    "        titles.append(book_title)\n",
    "        authors.append(book_author)\n",
    "        descriptions.append(book_desc)\n",
    "        languages.append(book_lang)\n",
    "        pages.append(book_page)\n",
    "        genres.append(\"computer_technology\")\n",
    "        publishers.append(book_publisher)\n",
    "        isbn10.append(book_isbn10)\n",
    "        isbn13.append(book_isbn13)\n",
    "        dimensions.append(book_dim)\n",
    "        shipping_weight.append(book_weight)\n",
    "        published_date.append(book_publication)\n",
    "        book_images.append(book_img_url)\n",
    "    print(\"...Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_location = 'D:/amazon_book_dataset.csv'\n",
    "df = pd.DataFrame({\n",
    "    'Book titles': titles, \n",
    "    'Book authors': authors, \n",
    "    'Book descriptions': descriptions, \n",
    "    'Languages': languages, \n",
    "    'Pages': pages, \n",
    "    'Genres': genres, \n",
    "    'Publishers': publishers, \n",
    "    'ISBN_10': isbn10, \n",
    "    'ISBN_13': isbn13, \n",
    "    'Dimensions': dimensions, \n",
    "    'Shipping_weight': shipping_weight, \n",
    "    'Published_date': published_date, \n",
    "    'Book_image': book_images,\n",
    "})\n",
    "df.drop_duplicates()\n",
    "df.to_csv(csv_file_location, index=False, encoding='utf-8', mode='a', header='False')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
